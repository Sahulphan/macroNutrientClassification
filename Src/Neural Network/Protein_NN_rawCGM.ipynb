{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 34)\n",
      "['ID', 'TruncatedID', 'Fat', 'Carb', 'Protein', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19', 'c20', 'c21', 'c22', 'c23', 'c24', 'c25', 'c26', 'c27', 'c28', 'c29']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "### reading data and printing the data ###\n",
    "data = pd.read_csv('RAW_CGM_Signal.csv',names=['ID','TruncatedID','Fat','Carb','Protein','c1','c2','c3','c4','c5','c6','c7','c8','c9','c10','c11','c12','c13','c14','c15','c16','c17','c18','c19','c20','c21','c22','c23','c24','c25','c26','c27','c28','c29'\n",
    "])\n",
    "# data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))\n",
    "\n",
    "\n",
    "### done with reading data and printing the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 11 18]\n",
      "[\"    '2133-001'\" \"    '2133-002'\" \"    '2133-004'\" \"    '2133-006'\"\n",
      " \"    '2133-008'\" \"    '2133-009'\" \"    '2133-010'\" \"    '2133-011'\"\n",
      " \"    '2133-012'\" \"    '2133-013'\" \"    '2133-015'\" \"    '2133-017'\"\n",
      " \"    '2133-018'\" \"    '2133-019'\" \"    '2133-020'\" \"    '2133-021'\"\n",
      " \"    '2133-022'\" \"    '2133-024'\" \"    '2133-025'\" \"    '2133-026'\"\n",
      " \"    '2133-028'\" \"    '2133-030'\" \"    '2133-032'\" \"    '2133-033'\"\n",
      " \"    '2133-035'\" \"    '2133-036'\" \"    '2133-037'\" \"    '2133-039'\"\n",
      " \"    '2133-040'\" \"    '2133-041'\"]\n"
     ]
    }
   ],
   "source": [
    "CHO_data = data.drop(['TruncatedID','Carb','Fat'], axis=1) #taking only the Carb target column\n",
    "print(CHO_data.Protein.unique())# Finding the unique values in that column\n",
    "print(CHO_data.ID.unique()) #finiding unique IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
      "[[21 33]\n",
      " [14 42]]\n",
      "True Negatives  21\n",
      "False Positives  33\n",
      "False Negatives  14\n",
      "True Positives  42\n",
      "class accuracies : 0.75 0.3888888888888889\n",
      "Unweighted accuracy : 0.5694444444444444\n",
      "\n",
      "\n",
      " built in accuracy 0.5727272727272728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nscores = cross_val_score(clf, X, Y, cv=10)\\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Low-High\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([9,18])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 9, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 18, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin']\n",
    "X =X.drop(['ID'], axis=1)\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin']\n",
    "X = X.values\n",
    "Y = Y.values\n",
    "# # X = np.array(df2[features])\n",
    "# # Y = np.array(df2['label'])\n",
    "groups = np.array(CHO_LH_data['ID'])\n",
    "\n",
    "# #clf = tree.DecisionTreeClassifier()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(12), random_state=1)\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print (logo.get_n_splits(X, Y, groups))\n",
    "\n",
    "y_pred = [-1 for x in range(len(Y))]\n",
    "\n",
    "for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_subject = clf.predict(X_test)\n",
    "    j = 0\n",
    "    for i in test_index:\n",
    "        y_pred[i] = y_pred_subject[j]\n",
    "        j+=1\n",
    "\n",
    "print (y_pred)\n",
    "\n",
    "print (confusion_matrix(Y, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, y_pred).ravel()\n",
    "\n",
    "print (\"True Negatives \", tn)\n",
    "print (\"False Positives \", fp)\n",
    "print (\"False Negatives \", fn)\n",
    "print (\"True Positives \", tp)\n",
    "\n",
    "yes_acc = tp/float(tp+fn)\n",
    "no_acc = tn/float(tn+fp)\n",
    "print (\"class accuracies :\", yes_acc, no_acc)\n",
    "un_acc = 0.5*(tp/float(tp+fn)) + 0.5*(tn/float(tn+fp))\n",
    "\n",
    "print (\"Unweighted accuracy :\", un_acc)\n",
    "print (\"\\n\\n built in accuracy\",accuracy_score(Y, y_pred))\n",
    "\n",
    "\"\"\"\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[[ 7 48]\n",
      " [ 6 50]]\n",
      "True Negatives  7\n",
      "False Positives  48\n",
      "False Negatives  6\n",
      "True Positives  50\n",
      "class accuracies : 0.8928571428571429 0.12727272727272726\n",
      "Unweighted accuracy : 0.5100649350649351\n",
      "\n",
      "\n",
      " built in accuracy 0.5135135135135135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nscores = cross_val_score(clf, X, Y, cv=10)\\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Medium-High\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([11,18])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 11, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 18, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin']\n",
    "X =X.drop(['ID'], axis=1)\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin']\n",
    "X = X.values\n",
    "Y = Y.values\n",
    "# # X = np.array(df2[features])\n",
    "# # Y = np.array(df2['label'])\n",
    "groups = np.array(CHO_LH_data['ID'])\n",
    "\n",
    "# #clf = tree.DecisionTreeClassifier()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(12), random_state=1)\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print (logo.get_n_splits(X, Y, groups))\n",
    "\n",
    "y_pred = [-1 for x in range(len(Y))]\n",
    "\n",
    "for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_subject = clf.predict(X_test)\n",
    "    j = 0\n",
    "    for i in test_index:\n",
    "        y_pred[i] = y_pred_subject[j]\n",
    "        j+=1\n",
    "\n",
    "print (y_pred)\n",
    "\n",
    "print (confusion_matrix(Y, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, y_pred).ravel()\n",
    "\n",
    "print (\"True Negatives \", tn)\n",
    "print (\"False Positives \", fp)\n",
    "print (\"False Negatives \", fn)\n",
    "print (\"True Positives \", tp)\n",
    "\n",
    "yes_acc = tp/float(tp+fn)\n",
    "no_acc = tn/float(tn+fp)\n",
    "print (\"class accuracies :\", yes_acc, no_acc)\n",
    "un_acc = 0.5*(tp/float(tp+fn)) + 0.5*(tn/float(tn+fp))\n",
    "\n",
    "print (\"Unweighted accuracy :\", un_acc)\n",
    "print (\"\\n\\n built in accuracy\",accuracy_score(Y, y_pred))\n",
    "\n",
    "\"\"\"\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[[30 24]\n",
      " [34 21]]\n",
      "True Negatives  30\n",
      "False Positives  24\n",
      "False Negatives  34\n",
      "True Positives  21\n",
      "class accuracies : 0.38181818181818183 0.5555555555555556\n",
      "Unweighted accuracy : 0.4686868686868687\n",
      "\n",
      "\n",
      " built in accuracy 0.46788990825688076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nscores = cross_val_score(clf, X, Y, cv=10)\\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Low-Medium\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([9,11])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 9, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 11, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin']\n",
    "X =X.drop(['ID'], axis=1)\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin']\n",
    "X = X.values\n",
    "Y = Y.values\n",
    "# # X = np.array(df2[features])\n",
    "# # Y = np.array(df2['label'])\n",
    "groups = np.array(CHO_LH_data['ID'])\n",
    "\n",
    "# #clf = tree.DecisionTreeClassifier()\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(12), random_state=1)\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "print (logo.get_n_splits(X, Y, groups))\n",
    "\n",
    "y_pred = [-1 for x in range(len(Y))]\n",
    "\n",
    "for train_index, test_index in logo.split(X, Y, groups=groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_subject = clf.predict(X_test)\n",
    "    j = 0\n",
    "    for i in test_index:\n",
    "        y_pred[i] = y_pred_subject[j]\n",
    "        j+=1\n",
    "\n",
    "print (y_pred)\n",
    "\n",
    "print (confusion_matrix(Y, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y, y_pred).ravel()\n",
    "\n",
    "print (\"True Negatives \", tn)\n",
    "print (\"False Positives \", fp)\n",
    "print (\"False Negatives \", fn)\n",
    "print (\"True Positives \", tp)\n",
    "\n",
    "yes_acc = tp/float(tp+fn)\n",
    "no_acc = tn/float(tn+fp)\n",
    "print (\"class accuracies :\", yes_acc, no_acc)\n",
    "un_acc = 0.5*(tp/float(tp+fn)) + 0.5*(tn/float(tn+fp))\n",
    "\n",
    "print (\"Unweighted accuracy :\", un_acc)\n",
    "print (\"\\n\\n built in accuracy\",accuracy_score(Y, y_pred))\n",
    "\n",
    "\"\"\"\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
