{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\projna.paromita\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "### importing bla bla bla ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "sb.set(style=\"white\")\n",
    "sb.set(style=\"whitegrid\", color_codes=True)\n",
    "import itertools\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold, LeaveOneOut\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### done with the imports ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 13)\n",
      "['ID', 'TruncatedID', 'Mean', 'SD', 'AUC', 'Peak', 'MaxIndex', 'Halfpk', 'Skew', 'HHMean', 'Fat', 'Carb', 'Protein']\n"
     ]
    }
   ],
   "source": [
    "### reading data and printing the data ###\n",
    "data = pd.read_csv('classical_feature.csv',names=['ID','TruncatedID','Mean','SD','AUC','Peak','MaxIndex','Halfpk','Skew','HHMean','Fat','Carb','Protein'\n",
    "])\n",
    "# data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))\n",
    "\n",
    "\n",
    "### done with reading data and printing the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18  9 11]\n",
      "['2133-002' '2133-022' '2133-020' '2133-004' '2133-010' '2133-015'\n",
      " '2133-040' '2133-013' '2133-008' '2133-019' '2133-001' '2133-024'\n",
      " '2133-011' '2133-018' '2133-006' '2133-032' '2133-025' '2133-017'\n",
      " '2133-028' '2133-039' '2133-021' '2133-030' '2133-033' '2133-037'\n",
      " '2133-026' '2133-012' '2133-036' '2133-035' '2133-041' '2133-009']\n"
     ]
    }
   ],
   "source": [
    "### CHO\n",
    "CHO_data = data.drop(['ID','Fat','Carb'], axis=1)\n",
    "print(CHO_data.Protein.unique())\n",
    "print(CHO_data.TruncatedID.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_trees = [int(x) for x in np.linspace(start=10, stop= 100, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(1,5,num=3)]\n",
    "# print(no_of_trees,max_depth)\n",
    "combination = [[x,y] for x in no_of_trees for y in max_depth]\n",
    "iiter = len(combination)\n",
    "# print(iiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold : 1\n",
      "90 5\n",
      "For fold : 2\n",
      "30 5\n",
      "For fold : 3\n",
      "80 5\n",
      "For fold : 4\n",
      "50 3\n",
      "For fold : 5\n",
      "20 5\n",
      "For fold : 6\n",
      "90 3\n",
      "For fold : 7\n",
      "90 5\n",
      "For fold : 8\n",
      "50 3\n",
      "For fold : 9\n",
      "100 3\n",
      "For fold : 10\n",
      "60 3\n",
      "For fold : 11\n",
      "80 3\n",
      "For fold : 12\n",
      "80 5\n",
      "For fold : 13\n",
      "60 5\n",
      "For fold : 14\n",
      "30 3\n",
      "For fold : 15\n",
      "100 3\n",
      "For fold : 16\n",
      "50 3\n",
      "For fold : 17\n",
      "30 3\n",
      "For fold : 18\n",
      "10 5\n",
      "For fold : 19\n",
      "80 5\n",
      "For fold : 20\n",
      "60 3\n",
      "For fold : 21\n",
      "40 3\n",
      "For fold : 22\n",
      "30 1\n",
      "For fold : 23\n",
      "50 5\n",
      "For fold : 24\n",
      "90 3\n",
      "For fold : 25\n",
      "80 5\n",
      "For fold : 26\n",
      "90 5\n",
      "For fold : 27\n",
      "100 3\n",
      "For fold : 28\n",
      "60 3\n",
      "For fold : 29\n",
      "50 3\n",
      "For fold : 30\n",
      "90 5\n",
      "The final accuracy is :  0.6805555555555556\n"
     ]
    }
   ],
   "source": [
    "###for LOW-HIGH\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([9,18])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 9, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 18, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin'] #Feature set\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin'] #target value/label\n",
    "\n",
    "values =['2133-002', '2133-022', '2133-020', '2133-004', '2133-010', '2133-015',\n",
    " '2133-040' ,'2133-013' ,'2133-008' ,'2133-019' ,'2133-001', '2133-024',\n",
    " '2133-011' ,'2133-018', '2133-006', '2133-032' ,'2133-025', '2133-017',\n",
    " '2133-028' ,'2133-039', '2133-021', '2133-030', '2133-033', '2133-037',\n",
    " '2133-026', '2133-012' ,'2133-036', '2133-035', '2133-041' ,'2133-009'] #needed for manual loso\n",
    "final_accuracy =[] #will be used for finding mean across nested cross validation\n",
    "for i in range(0,30): #as we have 30 IDs\n",
    "    print(\"For fold :\", i+1) #will print the current fold number, this is for initial check, can delete it\n",
    "    test =CHO_LH_data[CHO_LH_data['TruncatedID'].isin([values[i]])] #test data\n",
    "    train =CHO_LH_data[~CHO_LH_data['TruncatedID'].isin([values[i]])]#train data\n",
    "    X_train = train.loc[:, train.columns != 'CHO_bin'] #test feature\n",
    "    Y_train = train.loc[:, train.columns == 'CHO_bin'] #test label\n",
    "    X_test = test.loc[:, test.columns != 'CHO_bin']#train feature\n",
    "    \n",
    "    Y_test =test.loc[:, test.columns == 'CHO_bin']#train label\n",
    "    train_ids = X_train['TruncatedID']#needed for inner cross-validation\n",
    "  \n",
    "    train_ids = np.array(train_ids)#needed for inner cross-validation\n",
    "    train_ids = np.unique(train_ids)#needed for inner cross-validation\n",
    "#     print(train_ids[1])\n",
    "    X_train = X_train.drop(['TruncatedID'],axis = 1) #dropping this column as it is not a feature for classification\n",
    "    X_test = X_test.drop(['TruncatedID'],axis = 1)#dropping this column as it is not a feature for classification\n",
    "    max_acc = 0 #initializing maximum accuracy which will be needed later\n",
    "    for k in range(0,iiter): #ranges of decision tree depth\n",
    "        ypred_all = [] \n",
    "        for j in range(0,29): #as inner cross validation ha 29 IDs\n",
    "            inner_test = train[train['TruncatedID'].isin([train_ids[j]])] #validation set\n",
    "            inner_train = train[~train['TruncatedID'].isin([train_ids[j]])]#inner train set\n",
    "            xtr = inner_train.loc[:, inner_train.columns != 'CHO_bin'] #inner train set features\n",
    "            ytr = inner_train.loc[:, inner_train.columns == 'CHO_bin']# inner train set label\n",
    "            xvl = inner_test.loc[:, inner_test.columns != 'CHO_bin']#validation set features\n",
    "            yvl = inner_test.loc[:, inner_test.columns == 'CHO_bin']#validation set labels\n",
    "            xtr = xtr.drop(['TruncatedID'],axis = 1)#We dont need this column for classification \n",
    "            xvl = xvl.drop(['TruncatedID'],axis = 1)#We dont need this column for classification\n",
    "            rf = RandomForestClassifier(n_estimators=combination[k][0], max_depth= combination[k][1])\n",
    "            rf = rf.fit(xtr,ytr)\n",
    "            ypred = rf.predict(xvl)#prediction\n",
    "            ypred_all.append(accuracy_score(yvl,ypred))\n",
    "#         ypred_all = np.array(ypred_all)\n",
    "        ypred_mean = np.mean(ypred_all)#finding mean of all accuracy\n",
    "#         print(k,ypred_mean)\n",
    "        if max_acc<ypred_mean:#finding the depth which gives maximum accuracy\n",
    "            max_acc = ypred_mean\n",
    "            best_tree_no = combination[k][0]\n",
    "            best_depth = combination[k][1]\n",
    "#     print(max_acc, best_param)\n",
    "    print(best_tree_no, best_depth)\n",
    "    rf = RandomForestClassifier(n_estimators=best_tree_no, max_depth= best_depth) #using the hyperparameter from inner cross-validation to build decision tree for outer cross-validation\n",
    "    rf = rf.fit(X_train,Y_train)\n",
    "    Y_pred = rf.predict(X_test)\n",
    "#     print(classification_report(Y_test,Y_pred))\n",
    "#     print('Accuracy for test set :',accuracy_score(Y_test,Y_pred))\n",
    "    final_accuracy.append(accuracy_score(Y_test,Y_pred))\n",
    "print(\"The final accuracy is : \", np.mean(final_accuracy))#final result (mean of accuracies in outer CV)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold : 1\n",
      "90 3\n",
      "For fold : 2\n",
      "40 3\n",
      "For fold : 3\n",
      "50 3\n",
      "For fold : 4\n",
      "30 3\n",
      "For fold : 5\n",
      "40 3\n",
      "For fold : 6\n",
      "40 5\n",
      "For fold : 7\n",
      "50 5\n",
      "For fold : 8\n",
      "40 3\n",
      "For fold : 9\n",
      "40 3\n",
      "For fold : 10\n",
      "20 3\n",
      "For fold : 11\n",
      "60 5\n",
      "For fold : 12\n",
      "100 5\n",
      "For fold : 13\n",
      "70 3\n",
      "For fold : 14\n",
      "30 3\n",
      "For fold : 15\n",
      "90 3\n",
      "For fold : 16\n",
      "50 5\n",
      "For fold : 17\n",
      "90 5\n",
      "For fold : 18\n",
      "50 3\n",
      "For fold : 19\n",
      "100 3\n",
      "For fold : 20\n",
      "10 3\n",
      "For fold : 21\n",
      "50 5\n",
      "For fold : 22\n",
      "30 5\n",
      "For fold : 23\n",
      "40 5\n",
      "For fold : 24\n",
      "100 5\n",
      "For fold : 25\n",
      "10 3\n",
      "For fold : 26\n",
      "30 3\n",
      "For fold : 27\n",
      "50 3\n",
      "For fold : 28\n",
      "70 5\n",
      "For fold : 29\n",
      "10 3\n",
      "For fold : 30\n",
      "20 5\n",
      "The final accuracy is :  0.7277777777777777\n"
     ]
    }
   ],
   "source": [
    "###for Medium-HIGH\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([11,18])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 11, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 18, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin'] #Feature set\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin'] #target value/label\n",
    "\n",
    "values =['2133-002', '2133-022', '2133-020', '2133-004', '2133-010', '2133-015',\n",
    " '2133-040' ,'2133-013' ,'2133-008' ,'2133-019' ,'2133-001', '2133-024',\n",
    " '2133-011' ,'2133-018', '2133-006', '2133-032' ,'2133-025', '2133-017',\n",
    " '2133-028' ,'2133-039', '2133-021', '2133-030', '2133-033', '2133-037',\n",
    " '2133-026', '2133-012' ,'2133-036', '2133-035', '2133-041' ,'2133-009'] #needed for manual loso\n",
    "final_accuracy =[] #will be used for finding mean across nested cross validation\n",
    "for i in range(0,30): #as we have 30 IDs\n",
    "    print(\"For fold :\", i+1) #will print the current fold number, this is for initial check, can delete it\n",
    "    test =CHO_LH_data[CHO_LH_data['TruncatedID'].isin([values[i]])] #test data\n",
    "    train =CHO_LH_data[~CHO_LH_data['TruncatedID'].isin([values[i]])]#train data\n",
    "    X_train = train.loc[:, train.columns != 'CHO_bin'] #test feature\n",
    "    Y_train = train.loc[:, train.columns == 'CHO_bin'] #test label\n",
    "    X_test = test.loc[:, test.columns != 'CHO_bin']#train feature\n",
    "    \n",
    "    Y_test =test.loc[:, test.columns == 'CHO_bin']#train label\n",
    "    train_ids = X_train['TruncatedID']#needed for inner cross-validation\n",
    "  \n",
    "    train_ids = np.array(train_ids)#needed for inner cross-validation\n",
    "    train_ids = np.unique(train_ids)#needed for inner cross-validation\n",
    "#     print(train_ids[1])\n",
    "    X_train = X_train.drop(['TruncatedID'],axis = 1) #dropping this column as it is not a feature for classification\n",
    "    X_test = X_test.drop(['TruncatedID'],axis = 1)#dropping this column as it is not a feature for classification\n",
    "    max_acc = 0 #initializing maximum accuracy which will be needed later\n",
    "    for k in range(0,iiter): #ranges of decision tree depth\n",
    "        ypred_all = [] \n",
    "        for j in range(0,29): #as inner cross validation ha 29 IDs\n",
    "            inner_test = train[train['TruncatedID'].isin([train_ids[j]])] #validation set\n",
    "            inner_train = train[~train['TruncatedID'].isin([train_ids[j]])]#inner train set\n",
    "            xtr = inner_train.loc[:, inner_train.columns != 'CHO_bin'] #inner train set features\n",
    "            ytr = inner_train.loc[:, inner_train.columns == 'CHO_bin']# inner train set label\n",
    "            xvl = inner_test.loc[:, inner_test.columns != 'CHO_bin']#validation set features\n",
    "            yvl = inner_test.loc[:, inner_test.columns == 'CHO_bin']#validation set labels\n",
    "            xtr = xtr.drop(['TruncatedID'],axis = 1)#We dont need this column for classification \n",
    "            xvl = xvl.drop(['TruncatedID'],axis = 1)#We dont need this column for classification\n",
    "            rf = RandomForestClassifier(n_estimators=combination[k][0], max_depth= combination[k][1])\n",
    "            rf = rf.fit(xtr,ytr)\n",
    "            ypred = rf.predict(xvl)#prediction\n",
    "            ypred_all.append(accuracy_score(yvl,ypred))\n",
    "#         ypred_all = np.array(ypred_all)\n",
    "        ypred_mean = np.mean(ypred_all)#finding mean of all accuracy\n",
    "#         print(k,ypred_mean)\n",
    "        if max_acc<ypred_mean:#finding the depth which gives maximum accuracy\n",
    "            max_acc = ypred_mean\n",
    "            best_tree_no = combination[k][0]\n",
    "            best_depth = combination[k][1]\n",
    "#     print(max_acc, best_param)\n",
    "    print(best_tree_no, best_depth)\n",
    "    rf = RandomForestClassifier(n_estimators=best_tree_no, max_depth= best_depth) #using the hyperparameter from inner cross-validation to build decision tree for outer cross-validation\n",
    "    rf = rf.fit(X_train,Y_train)\n",
    "    Y_pred = rf.predict(X_test)\n",
    "#     print(classification_report(Y_test,Y_pred))\n",
    "#     print('Accuracy for test set :',accuracy_score(Y_test,Y_pred))\n",
    "    final_accuracy.append(accuracy_score(Y_test,Y_pred))\n",
    "print(\"The final accuracy is : \", np.mean(final_accuracy))#final result (mean of accuracies in outer CV)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold : 1\n",
      "20 1\n",
      "For fold : 2\n",
      "80 1\n",
      "For fold : 3\n",
      "30 1\n",
      "For fold : 4\n",
      "70 1\n",
      "For fold : 5\n",
      "10 1\n",
      "For fold : 6\n",
      "10 1\n",
      "For fold : 7\n",
      "10 1\n",
      "For fold : 8\n",
      "30 1\n",
      "For fold : 9\n",
      "80 1\n",
      "For fold : 10\n",
      "60 1\n",
      "For fold : 11\n",
      "70 1\n",
      "For fold : 12\n",
      "50 1\n",
      "For fold : 13\n",
      "90 1\n",
      "For fold : 14\n",
      "60 1\n",
      "For fold : 15\n",
      "70 1\n",
      "For fold : 16\n",
      "50 1\n",
      "For fold : 17\n",
      "20 1\n",
      "For fold : 18\n",
      "20 1\n",
      "For fold : 19\n",
      "60 1\n",
      "For fold : 20\n",
      "50 1\n",
      "For fold : 21\n",
      "40 1\n",
      "For fold : 22\n",
      "20 1\n",
      "For fold : 23\n",
      "30 1\n",
      "For fold : 24\n",
      "20 1\n",
      "For fold : 25\n",
      "20 1\n",
      "For fold : 26\n",
      "60 1\n",
      "For fold : 27\n",
      "50 1\n",
      "For fold : 28\n",
      "100 1\n",
      "For fold : 29\n",
      "50 1\n",
      "For fold : 30\n",
      "30 1\n",
      "The final accuracy is :  0.625\n"
     ]
    }
   ],
   "source": [
    "###for LOW-Medium\n",
    "\n",
    "CHO_LH_data = CHO_data[CHO_data['Protein'].isin([9,11])]\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein == 9, 'CHO_bin'] = 0\n",
    "CHO_LH_data.loc[CHO_LH_data.Protein== 11, 'CHO_bin'] = 1\n",
    "CHO_LH_data = CHO_LH_data.drop(['Protein'], axis=1)\n",
    "\n",
    "X = CHO_LH_data.loc[:, CHO_LH_data.columns != 'CHO_bin'] #Feature set\n",
    "Y = CHO_LH_data.loc[:, CHO_LH_data.columns == 'CHO_bin'] #target value/label\n",
    "\n",
    "values =['2133-002', '2133-022', '2133-020', '2133-004', '2133-010', '2133-015',\n",
    " '2133-040' ,'2133-013' ,'2133-008' ,'2133-019' ,'2133-001', '2133-024',\n",
    " '2133-011' ,'2133-018', '2133-006', '2133-032' ,'2133-025', '2133-017',\n",
    " '2133-028' ,'2133-039', '2133-021', '2133-030', '2133-033', '2133-037',\n",
    " '2133-026', '2133-012' ,'2133-036', '2133-035', '2133-041' ,'2133-009'] #needed for manual loso\n",
    "final_accuracy =[] #will be used for finding mean across nested cross validation\n",
    "for i in range(0,30): #as we have 30 IDs\n",
    "    print(\"For fold :\", i+1) #will print the current fold number, this is for initial check, can delete it\n",
    "    test =CHO_LH_data[CHO_LH_data['TruncatedID'].isin([values[i]])] #test data\n",
    "    train =CHO_LH_data[~CHO_LH_data['TruncatedID'].isin([values[i]])]#train data\n",
    "    X_train = train.loc[:, train.columns != 'CHO_bin'] #test feature\n",
    "    Y_train = train.loc[:, train.columns == 'CHO_bin'] #test label\n",
    "    X_test = test.loc[:, test.columns != 'CHO_bin']#train feature\n",
    "    \n",
    "    Y_test =test.loc[:, test.columns == 'CHO_bin']#train label\n",
    "    train_ids = X_train['TruncatedID']#needed for inner cross-validation\n",
    "  \n",
    "    train_ids = np.array(train_ids)#needed for inner cross-validation\n",
    "    train_ids = np.unique(train_ids)#needed for inner cross-validation\n",
    "#     print(train_ids[1])\n",
    "    X_train = X_train.drop(['TruncatedID'],axis = 1) #dropping this column as it is not a feature for classification\n",
    "    X_test = X_test.drop(['TruncatedID'],axis = 1)#dropping this column as it is not a feature for classification\n",
    "    max_acc = 0 #initializing maximum accuracy which will be needed later\n",
    "    for k in range(0,iiter): #ranges of decision tree depth\n",
    "        ypred_all = [] \n",
    "        for j in range(0,29): #as inner cross validation ha 29 IDs\n",
    "            inner_test = train[train['TruncatedID'].isin([train_ids[j]])] #validation set\n",
    "            inner_train = train[~train['TruncatedID'].isin([train_ids[j]])]#inner train set\n",
    "            xtr = inner_train.loc[:, inner_train.columns != 'CHO_bin'] #inner train set features\n",
    "            ytr = inner_train.loc[:, inner_train.columns == 'CHO_bin']# inner train set label\n",
    "            xvl = inner_test.loc[:, inner_test.columns != 'CHO_bin']#validation set features\n",
    "            yvl = inner_test.loc[:, inner_test.columns == 'CHO_bin']#validation set labels\n",
    "            xtr = xtr.drop(['TruncatedID'],axis = 1)#We dont need this column for classification \n",
    "            xvl = xvl.drop(['TruncatedID'],axis = 1)#We dont need this column for classification\n",
    "            rf = RandomForestClassifier(n_estimators=combination[k][0], max_depth= combination[k][1])\n",
    "            rf = rf.fit(xtr,ytr)\n",
    "            ypred = rf.predict(xvl)#prediction\n",
    "            ypred_all.append(accuracy_score(yvl,ypred))\n",
    "#         ypred_all = np.array(ypred_all)\n",
    "        ypred_mean = np.mean(ypred_all)#finding mean of all accuracy\n",
    "#         print(k,ypred_mean)\n",
    "        if max_acc<ypred_mean:#finding the depth which gives maximum accuracy\n",
    "            max_acc = ypred_mean\n",
    "            best_tree_no = combination[k][0]\n",
    "            best_depth = combination[k][1]\n",
    "#     print(max_acc, best_param)\n",
    "    print(best_tree_no, best_depth)\n",
    "    rf = RandomForestClassifier(n_estimators=best_tree_no, max_depth= best_depth) #using the hyperparameter from inner cross-validation to build decision tree for outer cross-validation\n",
    "    rf = rf.fit(X_train,Y_train)\n",
    "    Y_pred = rf.predict(X_test)\n",
    "#     print(classification_report(Y_test,Y_pred))\n",
    "#     print('Accuracy for test set :',accuracy_score(Y_test,Y_pred))\n",
    "    final_accuracy.append(accuracy_score(Y_test,Y_pred))\n",
    "print(\"The final accuracy is : \", np.mean(final_accuracy))#final result (mean of accuracies in outer CV)\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
